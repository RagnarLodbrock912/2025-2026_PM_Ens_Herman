dictionary2 = {'to': 54, 'o ': 66, ' s': 107, 'sh': 15, 'he': 130, 'er': 98, 'rl': 9, 'lo': 16, 'oc': 10, 'ck': 8, 'k ': 13, ' h': 134, 'ho': 45, 'ol': 16, 'lm': 7, 'me': 46, 'es': 57, 
's ': 142, 'e ': 250, ' i': 127, 'is': 65, ' a': 177, 'al': 32, 'lw': 3, 'wa': 31, 'ay': 9, 'ys': 6, ' t': 178, 'th': 147, ' w': 99, 'wo': 14, 'om': 31, 'ma': 34, 'an': 91, 'n.': 11, '. ': 59, 'i ': 43, 'ha': 73, 'av': 20, 've': 56, 'se': 59, 'el': 34, 'ld': 14, 'do': 21, 'm ': 16, 'ea': 30, 'ar': 56, 'rd': 10, 'd ': 140, 'hi': 69, 'im': 20, ' m': 72, 'en': 71, 'nt': 43, 'ti': 42, 'io': 23, 'on': 63, 'n ': 96, 'r ': 59, ' u': 20, 'un': 13, 'nd': 76, 'de': 27, 'ny': 4, 'y ': 78, ' o': 95, 'ot': 27, ' n': 26, 
'na': 11, 'am': 14, 'e.': 10, 'in': 118, ' e': 36, 'ey': 9, 'ye': 8, 'ec': 11, 'cl': 10, 'li': 26, 'ip': 1, 'ps': 3, ' p': 40, 'pr': 14, 're': 87, 'ed': 69, 'mi': 14, 'at': 62, 'te': 56, 'wh': 29, 'le': 42, 'of': 53, 'f ': 58, 'ex': 11, 'x.': 1, 'it': 70, 't ': 125, 'as': 55, 'no': 25, ' f': 41, 'fe': 6, 'lt': 5, 'em': 20, 'mo': 16, 'ak': 6, 'ki': 3, ' l': 29, 'ov': 6, 'fo': 15, 'or': 42, 'ir': 14, 'ne': 41, 'ad': 26, 'dl': 6, 'r.': 8, 'll': 29, 'l ': 25, 'ns': 23, 's,': 17, ', ': 99, 'pa': 18, 'rt': 7, 'ic': 32, 'cu': 8, 'ul': 23, 'la': 20, 'ly': 33, 'y,': 8, 'we': 22, 'ab': 10, 'bh': 1, 'rr': 3, ' c': 47, 'co': 18, 'd,': 12, 'ci': 12, ' b': 58, 'bu': 13, 'ut': 17, 'dm': 3, 
'ra': 19, 'bl': 13, 'ba': 5, 'nc': 14, 'ce': 34, 'd.': 11, 'ta': 14, 'ke': 17, 't,': 11, 'os': 10, 'st': 47, 'pe': 20, 'rf': 1, 'ct': 16, ' r': 30, 'so': 23, 'ni': 10, 'ng': 39, 'g ': 28, 'ob': 10, 'bs': 8, 'rv': 10, 'vi': 7, 'ac': 24, 'ch': 29, 'ee': 34, 'n,': 9, 'a ': 46, 'ou': 79, 'pl': 10, 'ms': 9, 'lf': 10, 'fa': 9, 'ls': 1, 'po': 20, 
'si': 28, 'ev': 10, 'sp': 7, 'ok': 5, 'ft': 5, 'ss': 23, 'sa': 11, 'wi': 23, 'h ': 38, ' g': 13, 'gi': 9, 'ib': 3, 'be': 32, 'sn': 1, 'gs': 3, 'r—': 2, '—e': 1, 'xc': 1, ' d': 46, 'dr': 9, 'aw': 5, ' v': 8, 'ei': 7, 'il': 14, 'fr': 12, 'ro': 37, 'n’': 4, '’s': 2, 'iv': 12, 's.': 14, 'tr': 24, 'ai': 20, 'su': 14, 'uc': 13, 'ru': 8, 'us': 18, 'ow': 35, 'wn': 11, 'ca': 20, 'fi': 11, 'dj': 1, 'ju': 4, 'mp': 10, 'od': 8, 'du': 8, 'di': 10, 'ig': 18, 'gh': 16, 'ht': 11, 'hr': 6, 'w ': 23, 'ub': 4, 'bt': 1, 'up': 16, 'ts': 11, 'gr': 1, 'ri': 29, 'um': 4, 'cr': 8, 'h-': 1, '-p': 1, 'tu': 11, 'ur': 28, 'rb': 2, 'bi': 4, ' y': 44, 'et': 22, 'm,': 2, 'r,': 9, ' q': 3, 'qu': 7, 'ue': 7, 
'ry': 13, 'y.': 5, '.\n': 8, '\n\n': 27, '\ni': 4, 'tt': 14, 'tl': 10, 'my': 21, 'ia': 7, 'ag': 13, 'ge': 15, 'if': 9, 'ap': 9, 'pp': 2, 'pi': 5, 'e-': 1, '-c': 2, 'p ': 7, 'rs': 12, 'ds': 5, 'hm': 1, 'uf': 1, 'ff': 6, 'ie': 15, 'b ': 1, 'oa': 1, 'rm': 6, 'ty': 3, 'bo': 5, 'oh': 1, 'l,': 5, 'dg': 2, 'oo': 15, 'ks': 2, 'rn': 7, 'ek': 2, 'tw': 5, 'mb': 5, 'ws': 1, 'ug': 8, 'g,': 5, 'rc': 2, 'rg': 3, 'gy': 1, ' k': 10, 'ep': 6, 'by': 6, 'ud': 5, 'dy': 3, 'e,': 17, 'cc': 6, 'mm': 2, 'xt': 3, 'ao': 2, 'va': 3, 'lu': 2, 'op': 5, 'gu': 4, 'oi': 3, 's:': 1, ': ': 1, 'mu': 5, 'tk': 1, 'br': 2, 'sf': 1, 'fu': 4, 'gn': 4, 'yo': 42, 'da': 7, 'kn': 7, 'ew': 6, '\no': 1, 't—': 1, '—i': 2, 
'h,': 1, ' 1': 1, '18': 1, '88': 2, '8—': 1, ' j': 5, 'jo': 1, ' (': 1, '(f': 1, 'e)': 1, '),': 1, 't.': 10, 'l-': 1, '-r': 1, 'rk': 9, 'id': 11, 'sc': 5, 'iz': 1, 'ze': 1, 'ga': 8, 'oy': 2, 'yi': 2, 'p,': 2, 'lh': 1, 'sw': 3, 'nk': 4, 'eh': 1, 'm.': 3, 'nn': 2, 'g-': 1, '\nh': 2, 'ef': 6, 's;': 1, '; ': 2, 'gl': 2, 'k,': 4, 'mc': 2, 'og': 
2, '\n“': 19, '“w': 4, 'ui': 5, 'u,': 1, ',”': 12, '” ': 17, ' “': 17, '“i': 7, 'u ': 29, 'pu': 1, 'u.': 1, '.”': 14, '”\n': 19, '“s': 2, 'n!': 1, '!”': 1, 'fl': 3, 'cy': 
1, 'go': 4, '“t': 8, 'w?': 1, '?”': 6, 'sy': 1, 'l?': 1, '“m': 2, 'i,': 1, 'h.': 1, 'nl': 1, 'o.': 1, 'lk': 2, 'hu': 3, 'sd': 1, 'df': 1, '’t': 2, 'ja': 1, 'kl': 1, 'bb': 
1, 'vo': 2, 'f,': 2, 'e;': 1, 'oe': 1, 'ik': 1, 'ix': 1, 'x ': 1, 'bv': 1, 'sl': 5, 'au': 3, 'eo': 4, 't-': 1, '-s': 1, 'sm': 3, 'lv': 1, 'lg': 1, 'p-': 1, '-h': 1, 'lp': 1, 'xp': 3, 'af': 2, '“q': 2, 'o,': 3, '“y': 1, 'xa': 3, 'eq': 2, '“f': 1, '“h': 2, 'n?': 1, 'e?': 1, 'y?': 1, '? ': 1, 'w.': 1, 'o!': 1, '! ': 1, 'w,': 1, 'k-': 1, '-t': 
1, '“r': 1, '\nt': 1, 'dd': 1, 'o-': 1, '-n': 1, 'ua': 2, 'o’': 1, '’c': 1, '“a': 1, 'ya': 1, 'eu': 1, 'gg': 1, 'sk': 1, 'k.': 1, 's?': 1, 'a.': 1, 'eg': 1, 'f.': 2, 't?': 1, 'wr': 3, '“p': 2, '—t': 1, 'l.': 1, '“e': 1, 'e”': 1, '“g': 2, 'g”': 1, 't”': 1}


dictionary1 = {' ': 1464, 'e': 794, 't': 542, 'a': 506, 'o': 498, 'i': 479, 's': 424, 'n': 415, 'h': 379, 'r': 352, 'd': 267, 'l': 247, 'u': 195, 'm': 185, 'c': 170, 'w': 160, 'y': 151, 'f': 133, ',': 111, 'p': 103, 'g': 103, 'b': 93, '.': 82, 'v': 68, '\n': 55, 'k': 49, '“': 36, '”': 36, 'x': 12, '-': 8, 'q': 7, '?': 7, 'j': 6, '’': 5, '—': 4, '8': 3, ';': 2, '!': 2, ':': 1, '1': 1, '(': 1, ')': 1, 'z': 1}

class Node:
    def __init__(self, value, weight):
        self.value = value
        self.weight = weight
        self.left = None
        self.right = None
        self.code = ""

def huffman(dictionary):
    arr = list()

    for el in dictionary.keys():
        arr.append(Node(el, dictionary[el]))

    while len(arr) > 1:
        arr.sort(key = lambda a: a.weight, reverse=True)
        new_node = Node("", arr[-1].weight + arr[-2].weight)
        new_node.left = arr[-1]
        new_node.right = arr[-2]

        arr.pop()
        arr.pop()
        arr.append(new_node)

    tree = arr[0]
    codes = {}

    def dfs(p, code):
        if p.left is None and p.right is None:
            codes[p.value] = code

        if p.left is not None:
            dfs(p.left, code + "0")

        if p.right is not None:
            dfs(p.right, code + "1")


    dfs(tree, "")

    return codes

codes1 = huffman(dictionary1)
codes2 = huffman(dictionary2)


filename = "text.txt"
with open(filename, "r", encoding='utf-8') as f:
    text = f.read()
    text = text.lower()

print(codes1)
print(codes2)
encoded1 = list()
encoded2 = list()

for i in range(0, len(text) - 2, 2):
    encoded2.append(codes2[text[i] + text[i + 1]])

for i in range(0, len(text) - 2):
    encoded1.append(codes1[text[i]])

print(encoded2)

import math

import math

class Node:
    def __init__(self, value, weight):
        self.value = value
        self.weight = weight
        self.left = None
        self.right = None
        self.code = ""

def huffman(dictionary):
    """Build Huffman codes from frequency dictionary"""
    arr = []
    
    # Create leaf nodes for each symbol
    for el in dictionary.keys():
        arr.append(Node(el, dictionary[el]))
    
    # Build tree from leaves to root
    while len(arr) > 1:
        arr.sort(key=lambda a: a.weight, reverse=True)
        new_node = Node("", arr[-1].weight + arr[-2].weight)
        new_node.left = arr[-1]
        new_node.right = arr[-2]
        
        arr.pop()
        arr.pop()
        arr.append(new_node)
    
    tree = arr[0]
    codes = {}
    
    # DFS to generate binary codes
    def dfs(p, code):
        if p.left is None and p.right is None:
            codes[p.value] = code
        if p.left is not None:
            dfs(p.left, code + "0")
        if p.right is not None:
            dfs(p.right, code + "1")
    
    dfs(tree, "")
    return codes

# ===== LOAD TEXT DATA =====
filename = "text.txt"
with open(filename, "r", encoding='utf-8') as f:
    text = f.read()
    text = text.lower()

# ===== BUILD HUFFMAN CODES =====
codes1 = huffman(dictionary1)  # Single-character codes
codes2 = huffman(dictionary2)  # Bigram codes

# ===== BASIC STATISTICS =====
char_count = sum(dictionary1.values())        # Total characters in text
bigram_count = sum(dictionary2.values())      # Total bigrams in text
alphabet_size_1 = len(dictionary1)           # Single-character alphabet size
alphabet_size_2 = len(dictionary2)           # Bigram alphabet size

# ======================================================================
# PART 1: SINGLE-CHARACTER HUFFMAN CODING
# ======================================================================

print("\n" + "="*60)
print(" " * 15 + "SINGLE-CHARACTER HUFFMAN CODING")
print("="*60)

# ----- Shannon Entropy (1st order) -----
total_freq_1 = sum(dictionary1.values())
entropy_1 = 0
for f in dictionary1.values():
    p = f / total_freq_1
    entropy_1 += -p * math.log2(p)

shannon_bits_1 = entropy_1 * total_freq_1

# ----- Huffman coding (1st order) -----
huffman_bits_1 = 0
for symbol, freq in dictionary1.items():
    huffman_bits_1 += freq * len(codes1[symbol])

# ----- Uniform coding -----
uniform_bits_per_char = math.ceil(math.log2(alphabet_size_1))
uniform_bits_1 = total_freq_1 * uniform_bits_per_char

# ----- ASCII coding -----
ascii_bits_1 = total_freq_1 * 8

# ----- OUTPUT RESULTS -----
print(f"\nTEXT STATISTICS:")
print(f"   • Text length: {char_count:,} characters")
print(f"   • Alphabet size: {alphabet_size_1} symbols")
print(f"   • Total symbols (with repetitions): {total_freq_1:,}")

print(f"\nSHANNON ENTROPY (1st ORDER):")
print(f"   • Entropy H₁: {entropy_1:.4f} bits/symbol")
print(f"   • Minimum bits required: {shannon_bits_1:.0f} bits")

print(f"\nCODING METHODS COMPARISON:")
print(f"   • ASCII (8 bits/symbol):      {ascii_bits_1:8,d} bits")
print(f"   • Uniform ({uniform_bits_per_char} bits/symbol):     {uniform_bits_1:8,d} bits")
print(f"   • Huffman (1st order):        {huffman_bits_1:8,d} bits")

print(f"\nHUFFMAN EFFICIENCY:")
print(f"   • Bits per character: {huffman_bits_1/char_count:.4f}")
print(f"   • Savings vs ASCII: {(1 - huffman_bits_1/ascii_bits_1)*100:.1f}%")
print(f"   • Savings vs Uniform: {(1 - huffman_bits_1/uniform_bits_1)*100:.1f}%")
print(f"   • Deviation from Shannon: {(huffman_bits_1/shannon_bits_1 - 1)*100:.1f}%")

# ======================================================================
# PART 2: BIGRAM HUFFMAN CODING
# ======================================================================

print("\n" + "="*60)
print(" " * 18 + "BIGRAM HUFFMAN CODING")
print("="*60)

# ----- Shannon Entropy for bigrams -----
total_freq_bigrams = sum(dictionary2.values())
entropy_bigrams = 0
for f in dictionary2.values():
    p = f / total_freq_bigrams
    entropy_bigrams += -p * math.log2(p)

shannon_bits_bigrams = entropy_bigrams * total_freq_bigrams

# ----- Huffman coding for bigrams -----
huffman_bits_bigrams = 0
for symbol, freq in dictionary2.items():
    huffman_bits_bigrams += freq * len(codes2[symbol])

# ----- Conditional Entropy H(X₂|X₁) - CORRECT 2nd order entropy -----
print(f"\nBIGRAM STATISTICS:")
print(f"   • Text length: {char_count:,} characters")
print(f"   • Number of bigrams: {bigram_count:,}")
print(f"   • Unique bigrams: {alphabet_size_2}")
print(f"   • Bigram coverage: {bigram_count/char_count*100:.1f}% of characters")

print(f"\nSHANNON ENTROPY (BIGRAMS):")
print(f"   • Entropy per bigram: {entropy_bigrams:.4f} bits/bigram")
print(f"   • Entropy per character (H₂ = H_bigram/2): {entropy_bigrams/2:.4f} bits/char")
print(f"   • Total information (Shannon): {shannon_bits_bigrams:.0f} bits")

print(f"\nHUFFMAN CODING FOR BIGRAMS:")
print(f"   • Total bits (bigram coding): {huffman_bits_bigrams:,} bits")
print(f"   • Bits per bigram: {huffman_bits_bigrams/bigram_count:.4f}")

# ===== CORRECT RECALCULATION PER CHARACTER =====
print(f"\nRECALCULATED PER CHARACTER:")

# Non-overlapping bigrams (step = 2)
characters_encoded_by_bigrams = bigram_count * 2
print(f"   • Characters encoded by bigrams: {characters_encoded_by_bigrams}")
print(f"   • Total characters in text: {char_count}")

# Bits per character
bits_per_char_huffman2 = huffman_bits_bigrams / characters_encoded_by_bigrams
bits_per_char_shannon = entropy_bigrams / 2

print(f"   • Shannon limit: {bits_per_char_shannon:.4f} bits/char")
print(f"   • Huffman (bigrams): {bits_per_char_huffman2:.4f} bits/char")

# Total bits for the ENTIRE text
total_bits_huffman2 = bits_per_char_huffman2 * char_count
print(f"   • Total bits for entire text: {total_bits_huffman2:.0f} bits")
print(f"   • (Original {huffman_bits_bigrams} bits were for {characters_encoded_by_bigrams} chars)")

# ======================================================================
# PART 3: COMPARISON OF BOTH METHODS
# ======================================================================

print("\n" + "="*60)
print(" " * 20 + "FINAL COMPARISON")
print("="*60)

huffman1_bits = 0
for symbol, freq in dictionary1.items():
    huffman1_bits += freq * len(codes1[symbol])

bits_per_char_huffman1 = huffman1_bits / char_count

print(f"\nSINGLE-CHARACTER HUFFMAN:")
print(f"   • Total bits: {huffman1_bits:,} bits")
print(f"   • Bits/character: {bits_per_char_huffman1:.4f}")
print(f"   • Efficiency: {entropy_1/bits_per_char_huffman1*100:.1f}% of Shannon limit")

print(f"\nBIGRAM HUFFMAN:")
print(f"   • Total bits: {total_bits_huffman2:.0f} bits")
print(f"   • Bits/character: {bits_per_char_huffman2:.4f}")
print(f"   • Efficiency: {bits_per_char_shannon/bits_per_char_huffman2*100:.1f}% of Shannon limit")

print(f"\nCOMPARISON RESULTS:")
improvement = (1 - bits_per_char_huffman2/bits_per_char_huffman1)*100
savings = huffman1_bits - total_bits_huffman2

print(f"   • Huffman 1st order: {huffman1_bits:,} bits")
print(f"   • Huffman 2nd order: {total_bits_huffman2:.0f} bits")
print(f"   • Absolute savings: {savings:.0f} bits")
print(f"   • Relative improvement: {improvement:.2f}%")
print(f"   • Bits saved per character: {bits_per_char_huffman1 - bits_per_char_huffman2:.4f}")

# ===== VERIFICATION =====
print("\n" + "="*60)
print(" " * 22 + "VERIFICATION")
print("="*60)

print(f"\nCHECK YOUR DICTIONARY2:")
print(f"   • Current bigram count: {bigram_count}")
print(f"   • Expected bigram count (non-overlapping): {char_count // 2}")
print(f"   • Expected bigram count (overlapping): {char_count - 1}")
print(f"   • Your dictionary2 uses: {'NON-overlapping' if bigram_count <= char_count//2 + 100 else 'OVERLAPPING'} bigrams")

print(f"\nSUMMARY:")
print(f"   • Single-character Huffman: {bits_per_char_huffman1:.4f} bits/char")
print(f"   • Bigram Huffman: {bits_per_char_huffman2:.4f} bits/char")
print(f"   • Theoretical 2nd order entropy: {bits_per_char_shannon:.4f} bits/char")
print(f"   • Improvement with bigrams: {improvement:.2f}%")

print("\n" + "="*60)
print(" " * 23 + "DONE")
print("="*60 + "\n")